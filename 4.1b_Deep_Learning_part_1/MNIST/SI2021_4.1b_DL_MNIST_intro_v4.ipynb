{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST exercise (handwritten printed digits recognition tutorial) ##\n",
    "**Goal: Introduction to Keras, convolution feature maps, and features**\n",
    "\n",
    "**Exercise:**\n",
    "    \n",
    "1. Review the steps of the code in this notebook\n",
    "2. Look for the model.Sequential statement \n",
    "   and fill in the paramaters for the first Conv2D layer: <br>\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    activation=..... \n",
    "    )\n",
    "<br>  use 16 for number of filters\n",
    "<br>  use 3,3 for kernel size\n",
    "<br>  use relu for activation\n",
    "\n",
    "3. run the notebook, observe the images of filter weights and activations (at end)\n",
    "4. Try changing the filter size for the first convolution layer to something large (like 9x9 or 16x16)\n",
    "5. compare the filters and activation to the 3x3 filter size\n",
    "\n",
    "<br>\n",
    "Question to consider: for 10 digits what is min number of filters needed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import numpy as np\n",
    "np.random.seed(1)  # for reproducibility\n",
    " \n",
    "from tensorflow import keras\n",
    "\n",
    "if 1:\n",
    " from tensorflow.keras.models import Sequential        #the standard stack of layers models\n",
    " from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten   #core layer  functions\n",
    " from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D     #convolution layer functions\n",
    " from tensorflow.keras import optimizers                             #For training \n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST data from Keras datasets\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('data loaded:'+str(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[0:1000,]  #only need smaller subset to get good results\n",
    "Y_train=Y_train[0:1000,]\n",
    "\n",
    "print('train shapes: \\n')\n",
    "print(X_train.shape)     #review the dimensions Note python3 uses print(X..) python 2 uses print X...\n",
    "print(Y_train.shape)\n",
    "print('img load done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Reshape input data ------------\n",
    "#  b/c Keras expects N-3D images (ie 4D matrix)\n",
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test  = X_test[:,:,:,np.newaxis]\n",
    "\n",
    "print('added dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert and put into 0-1 range\n",
    "X_train  = X_train.astype('float32')\n",
    "X_test   = X_test.astype('float32')\n",
    "\n",
    "#Scale 0 to 1  - or should we not scale\n",
    "X_train /= 255\n",
    "X_test  /= 255\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test  = keras.utils.to_categorical(Y_test,  10)\n",
    "\n",
    "# ------------- End loading and preparing data --------------\n",
    "#To confirm, we can print X_train's dimensions again:\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Set up Model ---------------------\n",
    "mymodel = keras.models.Sequential()\n",
    "mymodel.add(keras.layers.Convolution2D(___, \n",
    "                                       (___, ___),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation='_____', \n",
    "                                       input_shape=(28,28,1))) \n",
    "#  <<<<<<<<<------EXERCISE fill in blanks, \n",
    " \n",
    "print('modeldef and first conv layer done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Now add more Convolution layers\n",
    "mymodel.add(Convolution2D(16, (3, 3), strides=1, data_format=\"channels_last\", activation='relu'))\n",
    "mymodel.add(MaxPooling2D(pool_size=(2,2),strides=2,data_format=\"channels_last\")) #get Max over 2D region,and slide\n",
    "mymodel.add(Flatten())            #reorganize 2DxFilters output into 1D\n",
    "print('added more layers')\n",
    "\n",
    "#----------------Now add final classification layers\n",
    "mymodel.add(Dense(32, activation='relu'))  #enter number of hidden units (no good rule, but start with ~ num of previous output) \n",
    "mymodel.add(Dense(10, activation='softmax'))\n",
    "print('assemble model done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Now assemble (ie compile TensorFlow commands) and run -----\n",
    "mymodel.compile(loss='categorical_crossentropy',\n",
    "               optimizer='sgd',\n",
    "               metrics=['accuracy'])\n",
    "print('compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "myES_function = EarlyStopping(monitor='val_loss', mode='min', patience=5) #patience before stopping\n",
    "   \n",
    "#------------ Now Run Training\n",
    "fit_history=mymodel.fit(X_train, Y_train, #validation_split=0.20,\n",
    "          validation_data=(X_test,Y_test),\n",
    "          batch_size=32, epochs=20, verbose=1,callbacks=[myES_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline                   \n",
    "\n",
    "# list all data in history and print out performance\n",
    "print(fit_history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.axis([0 ,10, 0, 1])\n",
    "plt.plot(fit_history.history['accuracy'])\n",
    "plt.plot(fit_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val_test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view a sample image\n",
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "tmpimg=np.squeeze(X_train[0,:,:,:]).reshape((28,28))\n",
    "plt.imshow(tmpimg,'gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ GET WEIGHTS From Convolution Layer and make mosaic image \n",
    "Wlist   =mymodel.layers[0].get_weights()      \n",
    "W3D     =np.squeeze(Wlist[0])\n",
    "print(\"W3D shape Wlist[0]:\"+str(W3D.shape))\n",
    "W3Dchan =W3D.swapaxes(1,2).swapaxes(0,1)  #get the channels as 1st dimension;\n",
    "\n",
    "#plot mosaic of filters of \n",
    "ncol =4\n",
    "nrow =np.ceil(16/ncol)\n",
    "plt.figure()\n",
    "for i in range(W3Dchan.shape[0]):\n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(W3Dchan[i],'gray')\n",
    "   plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "print('done plotting weights mosaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ---------------- NOW Visualize the activations for the first training example --------\n",
    "#   1. gather activations from the model layers\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "layer_outputs     = [layer.output for layer in mymodel.layers[:]]\n",
    "my_model_actvtns  = keras.models.Model(inputs=mymodel.input, outputs=layer_outputs)\n",
    "x                 = np.expand_dims(X_train[0],0)           #set up a 4D input of 1 image training set \n",
    "my_actvtns_output = my_model_actvtns.predict(x)   #for each image get predictions/activatns\n",
    "\n",
    "print(str(len(my_actvtns_output))+ ' layers with output activations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.  Now output a mosaic of layer 1\n",
    "layeroutput3D      = np.squeeze(my_actvtns_output[0]) #<<---- -try different layer output     \n",
    "ncol =4\n",
    "nrow =np.ceil(16/ncol)\n",
    "plt.figure()\n",
    "for i in range(layeroutput3D.shape[2]):  \n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(layeroutput3D[:,:,i],'gray')\n",
    "   plt.axis('off')\n",
    "#plt.savefig(\"test.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "print('done plotting layer1 activation output mosaic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
