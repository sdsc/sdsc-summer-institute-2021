{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_hy9iCXlaax"
   },
   "source": [
    "# CNN Fine Tuning for Cats-Dogs Classification\n",
    "## CIML Summer Institute, UC San Diego\n",
    "Fine-tune VGG16 top layer (Conv block 5) and fully connected layers to classify cats vs. dogs. \n",
    "Adapted from tensorflow tutorials (https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb)\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NmDHijos0sW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, experimental\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjRHT_7ds0sX",
    "outputId": "67d5215b-c5a4-47fa-ee1e-4f13177ec0c7"
   },
   "outputs": [],
   "source": [
    "print (tf.__version__)\n",
    "!python --version\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5OAYvK0s0sX"
   },
   "outputs": [],
   "source": [
    "# Set logging level\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd4JjV5Cs0sX"
   },
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "seed = 1234\n",
    "\n",
    "# Disable hash randomization by specifying the value 0.\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set numpy random generator\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set python built-in random generator\n",
    "random.seed(seed)\n",
    "\n",
    "# Set tf global random seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set tensorflow graph-level random seed\n",
    "tf.compat.v1.random.set_random_seed(seed)\n",
    "\n",
    "# Potential randomness from CUDNN\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLToN9Hxs0sY"
   },
   "source": [
    "### Set image dimensions, location of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "IMG_SIZE = (img_width,img_height)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "# Location of images\n",
    "data_dir = os.getenv('HOME') + '/data/ml/catsVsDogs/'\n",
    "train_data_dir      = data_dir + 'train'\n",
    "validation_data_dir = data_dir + 'val'\n",
    "test_data_dir       = data_dir + 'test'\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data setup\n",
    "train_datagen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2,\n",
    "                                   zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "# Set up generator to read images found in subfolders of training data directory,\n",
    "# and indefinitely generate batches of image data (scaled).  This is for training data.\n",
    "train_generator = train_datagen.flow_from_directory((train_data_dir,target_size=<<FILL-IN>>, # img size we defined above\n",
    "                                                     batch_size = <<FILL-IN>> , class_mode='binary', # batch size we defined above\n",
    "                                                     shuffle = True, seed = <<FILL-IN>>)   # seed we defined above                     \n",
    "\n",
    "# Set up generator to generate batched of validation data for model\n",
    "validation_generator = validation_datagen.flow_from_directory(<<FILL-IN>>,target_size=<<FILL-IN>>,\n",
    "                                                              batch_size = <<TFILL-INODO>>,class_mode=<<FILL-IN>>,\n",
    "                                                              shuffle = <<FILL-IN>>, seed = <<FILL-IN>>) # no need to shuffle val data\n",
    "# Set up generator to generate batched of test data for model\n",
    "test_generator = test_datagen.flow_from_directory(<<FILL-IN>>,target_size=<<FILL-IN>>,\n",
    "                                                  batch_size = <<FILL-IN>>,class_mode=<<FILL-IN>>',\n",
    "                                                  shuffle = <<FILL-IN>>, seed = <<FILL-IN>>) # no need to shuffle val data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from feature extraction\n",
    "Load model saved from feature extraction.\n",
    "\n",
    "Weights in last convoluational layer and top model will be adjusted.  All other weights are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(<<FILL-IN>>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all weights of VGG16 model before conv block5 (layer 15)\n",
    "model.trainable = True\n",
    "for i, layers in enumerate(model.layers[0].layers):\n",
    "    if i < 15:layers.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Compile model with Adam optimizer with very slow learning rate,\n",
    "# Binary Cross-Entropy loss function and Accuracy metric \n",
    "model.compile(optimizer=<<FILL-IN>>, #use Adam optimizer with 0.000005 learning rate https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "              loss= <<FILL-IN>>, #use default Binary Cross-entropy loss https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
    "              metrics=[<<FILL-IN>>]) #use accuracy metrics; this will be printed out during training in each epochs https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy\n",
    "\n",
    "# Early Stopping to avoid overfitting and ModelCheckpoint to save the best model\n",
    "checkpoint_path = 'tmp/checkpoint'\n",
    "callbacks = [EarlyStopping(monitor=<<FILL-IN>>,patience=3,min_delta=0.001, #use val_loss to monitor during training https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "                           mode=<<FILL-IN>>), # we want to minimize val_loss\n",
    "             ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                             mode = 'min', save_best_only = True, \n",
    "                             save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "\n",
    "train_history = <<FILL-IN>> ## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model that was saved using ModelCheckpoint\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation history\n",
    "fig, axs = plt.subplots(1,2, figsize= (20,5))\n",
    "axs[0].plot(train_history.history['loss'])\n",
    "axs[0].plot(train_history.history['val_loss'])\n",
    "axs[0].set_title(\"Train, Val loss history\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].legend([\"Train Loss\",\"Val Loss\"])\n",
    "\n",
    "axs[1].plot(train_history.history['accuracy'])\n",
    "axs[1].plot(train_history.history['val_accuracy'])\n",
    "axs[1].set_title(\"Train, Val Accuracy history\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend([\"Train Accuracy\",\"Val Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_accuracy = model.evaluate(train_generator)\n",
    "print(\"Train data accuracy:\", train_accuracy)\n",
    "\n",
    "_, test_accuracy =  <<FILL-IN>> # evaluate test data\n",
    "print(\"Test data accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted value and the ground truth value of test data\n",
    "pred = (model.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_true= true, y_pred = pred, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(img_file):\n",
    "    \"\"\"load individual images\"\"\"\n",
    "    img = load_img(img_file, target_size = (img_width, img_height))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    img = img_to_array(img) / 255\n",
    "    img = np.expand_dims(img, axis = 0) #model input is (1,150,150,3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_loader(train_dir + 'test/cats/cat.1070.jpg')\n",
    "img_y_pred = <<FILL-IN>>\n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_loader(<<FILL-IN>>) # choose your favorite dog image\n",
    "img_y_pred = image_loader(img)\n",
    "print(<<FILL-IN>>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_loader(<<FILL-IN>>) # choose your favorite image"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "features_final_soln_tfl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
